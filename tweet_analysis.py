# -*- coding: utf-8 -*-
"""Tweet Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1advZDBEs5BWlx5ZB-3g67xHics9JTkS2
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

data = pd.read_excel('/content/drive/MyDrive/WiseWork/Task1/twitter_training (1).xlsx')

from matplotlib import pyplot as plt
import seaborn as sns

sentiment_counts = data['Sentiment'].value_counts()

plt.figure(figsize=(8, 6))
sns.barplot(x=sentiment_counts.values, y=sentiment_counts.index, palette='Dark2')

for i, count in enumerate(sentiment_counts.values):
    plt.text(count + 0.1, i, str(count), va='center')

sns.despine()

plt.xlabel('Count')
plt.ylabel('Sentiment')
plt.title('Distribution of Sentiments')

plt.show()

data.info()

data.describe()

data.isnull().sum()

data.dropna(subset=['Message'], inplace=True)

data.isnull().sum()

from matplotlib import pyplot as plt
import seaborn as sns

sentiment_counts = data['Sentiment'].value_counts()

plt.figure(figsize=(8, 6))
sns.barplot(x=sentiment_counts.values, y=sentiment_counts.index, palette='Dark2')

for i, count in enumerate(sentiment_counts.values):
    plt.text(count + 0.1, i, str(count), va='center')

sns.despine()

plt.xlabel('Count')
plt.ylabel('Sentiment')
plt.title('Distribution of Sentiments')

plt.show()

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
import string

# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# Initialize stemmer and set of stopwords
stemmer = PorterStemmer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    if isinstance(text, str):  # Check if text is a string
        # Convert to lowercase
        text = text.lower()

        # Remove punctuation
        text = text.translate(str.maketrans('', '', string.punctuation))

        # Tokenization
        tokens = word_tokenize(text)

        # Remove stopwords and short words
        tokens = [stemmer.stem(word) for word in tokens if word not in stop_words and len(word) > 2]

        return " ".join(tokens)
    else:
        return ""

# Apply preprocessing to the "Message" column
data['Processed_Message'] = data['Message'].apply(preprocess_text)

# Print a sample of the processed messages
print(data[['Message', 'Processed_Message']].head())

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.decomposition import TruncatedSVD
from scipy.sparse import csr_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression

"""**SVM**"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(data['Processed_Message'], data['Sentiment'], test_size=0.2, random_state=42)

# Initialize TF-IDF vectorizer
tfidf_vectorizer = TfidfVectorizer()

# Fit and transform the training data
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)

# Transform the testing data
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Reduce dimensionality using TruncatedSVD
svd = TruncatedSVD(n_components=100)  # Adjust n_components as needed
X_train_tfidf_svd = svd.fit_transform(X_train_tfidf)
X_test_tfidf_svd = svd.transform(X_test_tfidf)

# Convert to sparse matrix for memory efficiency
X_train_tfidf_sparse = csr_matrix(X_train_tfidf_svd)
X_test_tfidf_sparse = csr_matrix(X_test_tfidf_svd)

# Initialize and train a Linear Support Vector Machine (SVM) model with parallel processing
svm_model = LinearSVC(random_state=42)
svm_model.fit(X_train_tfidf_sparse, y_train)

# Predict on the testing data
Y_PRED = svm_model.predict(X_test_tfidf_sparse)

# Evaluate the model
accuracy = accuracy_score(y_test, Y_PRED)
print("Accuracy:", accuracy)

# Generate and print the classification report
report = classification_report(y_test, Y_PRED)
print("Classification Report:")
print(report)

# Generate confusion matrix
cm = confusion_matrix(y_test, Y_PRED)

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)

# Add labels, title, and ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])
plt.yticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])

# Display the plot
plt.tight_layout()
plt.show()

# Suppose you have a new message
new_message = "This is a positive day"

# Preprocess the new message
preprocessed_message = preprocess_text(new_message)  # Make sure to define preprocess_text function

# Transform the preprocessed message into a TF-IDF vector
tfidf_vector = tfidf_vectorizer.transform([preprocessed_message])

# Reduce dimensionality using TruncatedSVD
tfidf_svd = svd.transform(tfidf_vector)

# Convert to sparse matrix for memory efficiency
tfidf_sparse = csr_matrix(tfidf_svd)

# Predict the sentiment label for the new message
predicted_sentiment = svm_model.predict(tfidf_sparse)

# Print the predicted sentiment
print("Predicted Sentiment:", predicted_sentiment[0])

"""**Gradient Boosting**"""

# Initialize and train a Gradient Boosting model
gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
gb_model.fit(X_train_tfidf, y_train)

# Predict on the testing data
y_pred = gb_model.predict(X_test_tfidf)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Generate and print the classification report
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)

# Add labels, title, and ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])
plt.yticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])

# Display the plot
plt.tight_layout()
plt.show()

# Preprocess the new message
new_message = "kill!"
preprocessed_message = preprocess_text(new_message)

# Transform the preprocessed message into a TF-IDF vector
X_new_tfidf = tfidf_vectorizer.transform([preprocessed_message])

# Predict the sentiment label for the new message
predicted_sentiment = gb_model.predict(X_new_tfidf)

# Print the predicted sentiment
print("Predicted Sentiment:", predicted_sentiment[0])

"""**Naive Bayes**"""

# Initialize and train a Naive Bayes model (MultinomialNB for text data)
model = MultinomialNB()
model.fit(X_train_tfidf, y_train)

# Predict on the testing data
y_pre = model.predict(X_test_tfidf)

# Generate the classification report
report = classification_report(y_test, y_pre)

# Print the classification report
print("Classification Report:")
print(report)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pre)
print("Accuracy:", accuracy)

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pre)

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)

# Add labels, title, and ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])
plt.yticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])

# Display the plot
plt.tight_layout()
plt.show()

# Function to predict sentiment for new message
def predict_sentiment(new_message):
    # Preprocess the new message
    preprocessed_message = preprocess_text(new_message)

    # Transform the preprocessed message into a TF-IDF vector
    X_new_tfidf = tfidf_vectorizer.transform([preprocessed_message])

    # Predict the sentiment label for the new message
    predicted_sentiment = model.predict(X_new_tfidf)

    return predicted_sentiment[0]

# Test the prediction function
new_message = "This product is great!"
predicted_sentiment = predict_sentiment(new_message)
print("Predicted Sentiment:", predicted_sentiment)

"""**Logistic Regression**"""

# Training the Logistic Regression model
logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train_tfidf, y_train)

# Making predictions
Y_predL = logreg.predict(X_test_tfidf)

# Model evaluation
accuracy = accuracy_score(y_test, Y_predL)
print("Accuracy:", accuracy)

print("\nClassification Report:")
print(classification_report(y_test, Y_predL))

# Generate confusion matrix
cm = confusion_matrix(y_test, Y_predL)

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)

# Add labels, title, and ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])
plt.yticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])

# Display the plot
plt.tight_layout()
plt.show()

# Function to predict sentiment for new message
def predict_sentiment(new_message):
    # Transform the new message into a TF-IDF vector
    new_message_tfidf = tfidf_vectorizer.transform([new_message])

    # Predict the sentiment label for the new message
    predicted_sentiment = logreg.predict(new_message_tfidf)

    return predicted_sentiment[0]

# Test the prediction function
new_message = "This product is great!"
predicted_sentiment = predict_sentiment(new_message)
print("Predicted Sentiment:", predicted_sentiment)

"""**Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

# Training the Decision Tree model
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(X_train_tfidf, y_train)

# Making predictions
y_preD = decision_tree.predict(X_test_tfidf)

# Model evaluation
accuracy = accuracy_score(y_test, y_preD)
print("Accuracy:", accuracy)

print("\nClassification Report:")
print(classification_report(y_test, y_preD))

# Generate confusion matrix
cm = confusion_matrix(y_test, y_preD)

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)

# Add labels, title, and ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])
plt.yticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])

# Display the plot
plt.tight_layout()
plt.show()

# Function to preprocess and predict sentiment
def predict_sentiment(new_message):
    # Transform the new message into a TF-IDF vector
    new_message_tfidf = tfidf_vectorizer.transform([new_message])

    # Predict the sentiment label for the new message
    predicted_sentiment = decision_tree.predict(new_message_tfidf)

    return predicted_sentiment[0]

# Test the prediction function with a new message
new_message = "This product is amazing!"
predicted_sentiment = predict_sentiment(new_message)
print("Predicted Sentiment:", predicted_sentiment)

"""**Random Forest Classifier**"""

from sklearn.ensemble import RandomForestClassifier

# Initialize and train a Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_tfidf, y_train)

# Predict on the testing data
y_pRed = rf_model.predict(X_test_tfidf)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pRed)
print("Accuracy:", accuracy)

# Generate and print the classification report
report = classification_report(y_test, y_pRed)
print("Classification Report:")
print(report)

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pRed)

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)

# Add labels, title, and ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])
plt.yticks(ticks=[0, 1, 2,3], labels=['Negative', 'Neutral', 'Positive','Irrelevant'])

# Display the plot
plt.tight_layout()
plt.show()

# Function to predict sentiment for new message
def predict_sentiment(new_message):
    # Transform the new message into a TF-IDF vector
    new_message_tfidf = tfidf_vectorizer.transform([new_message])

    # Predict the sentiment label for the new message
    predicted_sentiment = rf_model.predict(new_message_tfidf)

    return predicted_sentiment[0]

# Test the prediction function
new_message = "This is awesome  !"
predicted_sentiment = predict_sentiment(new_message)
print("Predicted Sentiment:", predicted_sentiment)

import matplotlib.pyplot as plt

# Accuracy scores for each model
models = ['SVM', 'Gradient Boosting','Naive Bayes','Logistic Regression','Decision Tree','Random Forest']
accuracy_scores = [0.49837837837837846, 0.5255405405405406, 0.6885135135135135, 0.7553378378378378,0.7786486486486487, 0.8994594594594595]

# Create a line plot
plt.figure(figsize=(10, 6))
plt.plot(models, accuracy_scores, marker='o', linestyle='-', color='b', label='Accuracy')
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Accuracy Comparison of Different Models')
plt.ylim(0, 1)
plt.grid(True)
plt.legend()
plt.tight_layout()

# Adding individual data points to the line plot
for i, txt in enumerate(accuracy_scores):
    plt.annotate(f"{txt:.3f}", (models[i], accuracy_scores[i]), textcoords="offset points", xytext=(0,10), ha='center')

# Show plot
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

df = pd.DataFrame(data)

# Group by 'Pl' and 'Sentiment' and get the count of each group
sentiment_counts = df.groupby(['Pl', 'Sentiment']).size().unstack(fill_value=0)

# Plotting
sentiment_counts.plot(kind='bar', stacked=True, figsize=(10, 6))
plt.title('Sentiment Counts by Place')
plt.xlabel('Place')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend(title='Sentiment')
plt.tight_layout()
plt.show()

df = pd.DataFrame(data)

# Group by 'Pl' and 'Sentiment' and get the count of each group
sentiment_counts = df.groupby(['Pl', 'Sentiment']).size().unstack(fill_value=0)

# Plotting
sentiment_counts.plot(kind='bar', figsize=(10, 6))
plt.title('Sentiment Distribution')
plt.xlabel('Place')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend(title='Sentiment')
plt.tight_layout()
plt.show()